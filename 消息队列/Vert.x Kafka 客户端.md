# Vert.x Kafka å®¢æˆ·ç«¯

è¯¥ç»„ä»¶æä¾›äº† Kafka å®¢æˆ·ç«¯ï¼Œ å¯ä»¥ç”¨ä¸ç»™ [Apache Kafka](https://kafka.apache.org/) é›†ç¾¤å‘é€ä¿¡æ¯ï¼Œæˆ–ä»ä¸­è¯»å–ä¿¡æ¯ã€‚

ä½œä¸ºæ¶ˆè´¹è€…ï¼Œæ¥å£æä¾›äº†è®¢é˜…ä¸»é¢˜åˆ†åŒºï¼Œå¹¶å¼‚æ­¥åœ° æ¥æ”¶æ¶ˆæ¯ï¼Œæˆ–å°†æ¶ˆæ¯ä½œä¸ºæµè¿›è¡Œå¤„ç†ï¼ˆç”šè‡³å¯ä»¥åšåˆ°ä¸­æ­¢æˆ–é‡å¯æ•°æ®æµï¼‰çš„æ–¹æ³•ã€‚

ä½œä¸ºç”Ÿäº§è€…ï¼Œæ¥å£æä¾›äº†æµå¼å‘ä¸»é¢˜åˆ†åŒºå‘é€æ¶ˆæ¯çš„æ–¹æ³•ã€‚

## ä½¿ç”¨ Vert.x çš„ Kafka å®¢æˆ·ç«¯

ä¸ºäº†ä½¿ç”¨è¯¥ç»„ä»¶ï¼Œ éœ€è¦åœ¨æ‚¨çš„æ„å»ºæè¿°æ–‡ä»¶ä¸­çš„ä¾èµ–é…ç½®ä¸­æ·»åŠ å¦‚ä¸‹å†…å®¹ï¼š

- Maven (åœ¨æ‚¨çš„ `pom.xml`):

```xml
<dependency>
 <groupId>io.vertx</groupId>
 <artifactId>vertx-kafka-client</artifactId>
 <version>4.3.5</version>
</dependency>
```

- Gradle (åœ¨æ‚¨çš„ `build.gradle` æ–‡ä»¶ä¸­):

```groovy
compile io.vertx:vertx-kafka-client:4.3.5
```

## åˆ›å»º kafka å®¢æˆ·ç«¯

åˆ›å»º kafka çš„æ¶ˆè´¹è€…å’Œç”Ÿäº§è€…çš„æ–¹å¼éå¸¸è¯¦ç»†ï¼Œå®ƒä»¬éƒ½åŸºäºåŸç”Ÿçš„ kafka çš„å®¢æˆ·ç«¯åº“å·¥ä½œã€‚

åœ¨åˆ›å»ºæ—¶ï¼Œéœ€è¦è¿›è¡Œå¾ˆå¤šé…ç½®ï¼Œè¿™äº›é…ç½®å¯ä»¥å‚è€ƒ Apache Kafka æ–‡æ¡£ï¼Œ å‚è§ [æ¶ˆè´¹è€…](https://kafka.apache.org/documentation/#newconsumerconfigs) å’Œ [ç”Ÿäº§è€…](https://kafka.apache.org/documentation/#producerconfigs).

ä¸ºäº†æ–¹ä¾¿é…ç½®ï¼Œ æ‚¨å¯ä»¥å°†å‚æ•°æ”¾ç½®åœ¨ä¸€ä¸ª Map å®¹å™¨ä¸­ï¼Œå¹¶åœ¨è°ƒç”¨ `KafkaConsumer` å’Œ `KafkaProducer` çš„é™æ€åˆ›å»ºæ–¹æ³•æ—¶ä¼ å…¥ã€‚

```java
Map<String, String> config = new HashMap<>();
config.put("bootstrap.servers", "localhost:9092");
config.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
config.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
config.put("group.id", "my_group");
config.put("auto.offset.reset", "earliest");
config.put("enable.auto.commit", "false");

// ä½¿ç”¨æ¶ˆè´¹è€…å’Œ Apache Kafka äº¤äº’
KafkaConsumer<String, String> consumer = KafkaConsumer.create(vertx, config);
```

åœ¨ä»¥ä¸Šä»£ç ä¸­ï¼Œæˆ‘ä»¬ä¼ å…¥äº†ä¸€ä¸ª Map å®¹å™¨å®ä¾‹ä½œä¸ºåˆ›å»º `KafkaConsumer` å¯¹è±¡å®ä¾‹æ—¶ çš„å‚æ•°ï¼Œè¿™æ ·å¯ä»¥æŒ‡å®šè¦è¿æ¥çš„ kafka èŠ‚ç‚¹åˆ—è¡¨ï¼ˆè¿™é‡Œåªæœ‰ä¸€ä¸ªï¼‰çš„åœ°å€å’Œ æ¯ä¸ªæ¥æ”¶åˆ°çš„æ¶ˆæ¯çš„é”®å’Œå†…å®¹çš„ååºåˆ—åŒ–å™¨ã€‚

åˆ›å»º kafka ç”Ÿäº§è€…åœ°æ–¹æ³•ä¹Ÿå¤§è‡´ç›¸åŒã€‚

```java
Map<String, String> config = new HashMap<>();
config.put("bootstrap.servers", "localhost:9092");
config.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
config.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
config.put("acks", "1");

// ä½¿ç”¨ç”Ÿäº§è€…å’Œ Apache Kafka äº¤äº’
KafkaProducer<String, String> producer = KafkaProducer.create(vertx, config);
```

> **ğŸ“æ³¨æ„:** åˆ›å»º `KafkaConsumer` çš„äº‹ä»¶å¾ªç¯å°†æ˜¯å¤„ç†å…¶æ¶ˆæ¯çš„äº‹ä»¶å¾ªç¯ã€‚ ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨å¸Œæœ›åœ¨ Verticle çš„äº‹ä»¶å¾ªç¯ä¸Šå¤„ç†æ¶ˆæ¯ï¼Œè¯·åœ¨ Verticle çš„ start æ–¹æ³•ä¸­åˆ›å»º Kafka Consumerã€‚

## åŠ å…¥ä¸€ä¸ªæ¶ˆè´¹è€…ç¾¤ç»„å¹¶ä»ä¸»é¢˜ä¸­æ¥æ”¶æ¶ˆæ¯

è¦å¼€å§‹ä» kafka çš„ä¸»é¢˜ä¸­æ¥æ”¶æ¶ˆæ¯ï¼Œ æ¶ˆè´¹è€…éœ€è¦ä½¿ç”¨ `subscribe` æ–¹æ³•å» ä½œä¸ºä¸€ä¸ªæ¶ˆè´¹è€…ç¾¤ç»„ï¼ˆç¾¤ç»„åœ¨åˆ›å»ºæ—¶çš„å±æ€§è®¾ç½®é‡ŒæŒ‡å®šï¼‰çš„ä¸€å‘˜å»è®¢é˜…ä¸€ç»„ä¸»é¢˜ã€‚

æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨ `subscribe` æ–¹æ³•å» æŒ‡å®šä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼ï¼Œå¹¶è®¢é˜…æ‰€æœ‰åŒ¹é…è¯¥æ­£åˆ™è¡¨è¾¾å¼çš„ä¸»é¢˜ã€‚

ä¸ºäº†æ³¨å†Œä¸€ä¸ªå¤„ç†å™¨å»å¤„ç†æ¥æ”¶åˆ°çš„æ¶ˆæ¯ï¼Œæ‚¨éœ€è¦ä½¿ç”¨ `handler` æ–¹æ³•ã€‚

```java
consumer.handler(record -> {
  System.out.println("Processing key=" + record.key() + ",value=" + record.value() +
    ",partition=" + record.partition() + ",offset=" + record.offset());
});

// è®¢é˜…ä¸€ç»„ä¸»é¢˜
Set<String> topics = new HashSet<>();
topics.add("topic1");
topics.add("topic2");
topics.add("topic3");
consumer.subscribe(topics);

// æˆ–ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼
Pattern pattern = Pattern.compile("topic\\d");
consumer.subscribe(pattern);

// æˆ–ä»…è®¢é˜…ä¸€ä¸ªä¸»é¢˜
consumer.subscribe("a-single-topic");
```

æ‚¨å¯ä»¥åœ¨è°ƒç”¨ `subscribe()` æ–¹æ³•çš„å‰åæ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨ï¼› ç›´åˆ°æ‚¨è°ƒç”¨äº†è¯¥æ–¹æ³•å¹¶æ³¨å†Œäº†æ¶ˆæ¯å¤„ç†å™¨åï¼Œæ¶ˆæ¯æ‰ä¼š å¼€å§‹è¢«æ¶ˆè´¹ã€‚ ä¸¾ä¸ªä¾‹å­ï¼Œæ‚¨å¯ä»¥å…ˆè°ƒç”¨ `subscribe()` æ–¹æ³•ï¼Œå†è°ƒç”¨ `seek()` æ–¹æ³•ï¼Œæœ€åè°ƒç”¨ `handler()` æ–¹æ³• ï¼Œè¿™æ ·æ‚¨å¯ä»¥åœ¨ä¸€ä¸ªç‰¹å®šçš„åç§»å¤„å¼€å§‹æ¶ˆè´¹æ¶ˆæ¯ã€‚

æ¶ˆæ¯å¤„ç†å™¨ä¹Ÿå¯ä»¥åœ¨è®¢é˜…æ—¶æ³¨å†Œï¼Œè¿™æ ·æ‚¨å°±å¯ä»¥è·å–è®¢é˜…çš„ç»“æœå¹¶å½“æ“ä½œå®Œæˆæ—¶ æ”¶åˆ°é€šçŸ¥ã€‚

```java
consumer.handler(record -> {
  System.out.println("Processing key=" + record.key() + ",value=" + record.value() +
    ",partition=" + record.partition() + ",offset=" + record.offset());
});

// è®¢é˜…ä¸€ç»„ä¸»é¢˜
Set<String> topics = new HashSet<>();
topics.add("topic1");
topics.add("topic2");
topics.add("topic3");
consumer
  .subscribe(topics)
  .onSuccess(v ->
    System.out.println("subscribed")
  ).onFailure(cause ->
    System.out.println("Could not subscribe " + cause.getMessage())
  );

// æˆ–ä»…è®¢é˜…ä¸€ä¸ªä¸»é¢˜
consumer
  .subscribe("a-single-topic")
  .onSuccess(v ->
    System.out.println("subscribed")
  ).onFailure(cause ->
    System.out.println("Could not subscribe " + cause.getMessage())
  );
```

é€šè¿‡ä½¿ç”¨æ¶ˆè´¹è€…ç¾¤ç»„ï¼ŒKafka é›†ç¾¤ä¼šå°†åŒä¸€ä¸ªæ¶ˆè´¹è€…ç¾¤ç»„ä¸‹çš„å…¶ä»–æ¶ˆè´¹è€…æ­£åœ¨ä½¿ç”¨çš„åˆ†åŒº åˆ†é…ç»™è¯¥æ¶ˆè´¹è€…ï¼Œ å› æ­¤åˆ†åŒºå¯ä»¥åœ¨æ¶ˆè´¹è€…ç¾¤ç»„ä¸­ä¼ æ’­ã€‚

Kafka é›†ç¾¤ä¼šåœ¨æ¶ˆè´¹è€…ç¦»å¼€é›†ç¾¤æ—¶ï¼ˆæ­¤æ—¶åŸæ¶ˆè´¹è€…çš„åˆ†åŒºå¯ä»¥åˆ†é…ç»™å…¶ä»–æ¶ˆè´¹è€…ï¼‰æˆ– æ–°çš„æ¶ˆè´¹è€…åŠ å…¥é›†ç¾¤æ—¶ï¼ˆæ–°æ¶ˆè´¹è€…çš„éœ€è¦ç”³è¯·åˆ†åŒºæ¥è¯»å–ï¼‰é‡æ–°å¹³è¡¡åˆ†åŒºã€‚

æ‚¨å¯ä»¥ç»™ `KafkaConsumer` æ³¨å†Œä¸€ä¸ªå¤„ç†å™¨ï¼Œè¿™æ · ä¼šåœ¨ kafka é›†ç¾¤ç»™æ¶ˆè´¹è€…åˆ†é…æˆ–æ’¤å›ä¸»é¢˜åˆ†åŒºæ—¶æ”¶åˆ°é€šçŸ¥ï¼Œä½¿ç”¨ `partitionsRevokedHandler` å’Œ `partitionsAssignedHandler` æ–¹æ³•æ³¨å†Œè¯¥å¤„ç†å™¨ã€‚

```java
consumer.handler(record -> {
  System.out.println("Processing key=" + record.key() + ",value=" + record.value() +
    ",partition=" + record.partition() + ",offset=" + record.offset());
});

// æ³¨å†Œä¸»é¢˜åˆ†åŒºæ’¤å›å’Œåˆ†é…çš„å¤„ç†å™¨
consumer.partitionsAssignedHandler(topicPartitions -> {
  System.out.println("Partitions assigned");
  for (TopicPartition topicPartition : topicPartitions) {
    System.out.println(topicPartition.getTopic() + " " + topicPartition.getPartition());
  }
});

consumer.partitionsRevokedHandler(topicPartitions -> {
  System.out.println("Partitions revoked");
  for (TopicPartition topicPartition : topicPartitions) {
    System.out.println(topicPartition.getTopic() + " " + topicPartition.getPartition());
  }
});

// è®¢é˜…ä¸»é¢˜
consumer
  .subscribe("test")
  .onSuccess(v ->
    System.out.println("subscribed")
  ).onFailure(cause ->
    System.out.println("Could not subscribe " + cause.getMessage())
  );
```

åœ¨åŠ å…¥ä¸€ä¸ªæ¶ˆè´¹è€…ç¾¤ç»„æ¥æ”¶æ¶ˆæ¯åï¼Œ æ¶ˆè´¹è€…å¯ä»¥é€‰æ‹©ä½¿ç”¨ `unsubscribe` æ–¹æ³• ç¦»å¼€ç¾¤ç»„ï¼Œè¿™æ ·å°±ä¸ä¼šå†æ”¶åˆ°æ¶ˆæ¯

```java
consumer.unsubscribe();
```

æ‚¨è¿˜å¯ä»¥è®¾ç½®ä¸€ä¸ªå¤„ç†å™¨æ¥å¤„ç†é€€å‡ºçš„ç»“æœ

```java
consumer
  .unsubscribe()
  .onSuccess(v ->
    System.out.println("Consumer unsubscribed")
  );
```

## è¯·æ±‚æŒ‡å®šä¸»é¢˜åˆ†åŒºä»¥æ¥æ”¶æ¶ˆæ¯

åœ¨æ¥æ”¶æ¶ˆæ¯æ—¶ï¼Œé™¤äº†åŠ å…¥æ¶ˆè´¹è€…ç¾¤ç»„ï¼Œ æ¶ˆè´¹è€…ä¹Ÿå¯ä»¥ä¸»åŠ¨è¯·æ±‚ä¸€ä¸ª ç‰¹å®šçš„ä¸»é¢˜åˆ†åŒºã€‚ å½“æ¶ˆè´¹è€…å¹¶ä¸åœ¨ä¸€ä¸ªæ¶ˆè´¹è€…ç¾¤ç»„å†…ï¼Œ é‚£ä¹ˆåº”ç”¨å°±ä¸èƒ½ ä¾èµ– kafka çš„é‡å¹³è¡¡ç‰¹æ€§ã€‚

æ‚¨å¯ä»¥ä½¿ç”¨ `assign` æ–¹æ³• å»è¯·æ±‚ç‰¹å®šçš„åˆ†åŒºã€‚

```java
consumer.handler(record -> {
  System.out.println("key=" + record.key() + ",value=" + record.value() +
    ",partition=" + record.partition() + ",offset=" + record.offset());
});

//
Set<TopicPartition> topicPartitions = new HashSet<>();
topicPartitions.add(new TopicPartition()
  .setTopic("test")
  .setPartition(0));

// è¯·æ±‚åˆ†é…ç‰¹å®šçš„åˆ†åŒº
consumer
  .assign(topicPartitions)
  .onSuccess(v -> System.out.println("Partition assigned"))
  // æˆåŠŸåä¼šä»è¯¥åˆ†åŒºè·å–æ¶ˆæ¯
  .compose(v -> consumer.assignment())
  .onSuccess(partitions -> {
    for (TopicPartition topicPartition : partitions) {
      System.out.println(topicPartition.getTopic() + " " + topicPartition.getPartition());
    }
  });
```

ä½¿ç”¨ `subscribe()` æ–¹æ³•æ—¶ï¼Œ æ‚¨å¯ä»¥åœ¨è°ƒç”¨ `assign()` æ–¹æ³•ä¹‹å‰æˆ–ä¹‹åæ³¨å†Œæ¥æ”¶æ¶ˆæ¯å¤„ç†å™¨ï¼› å› ä¸ºæ¶ˆæ¯åªä¼šåœ¨ä¸¤ä¸ªæ–¹æ³•éƒ½ç”Ÿæ•ˆåæ‰ä¼šè¢«æ¶ˆè´¹ã€‚ ä¸¾ä¸ªä¾‹å­ï¼Œæ‚¨å¯ä»¥å…ˆè°ƒç”¨ `assign()` æ–¹æ³•ï¼Œ å†è°ƒç”¨ `seek()` æ–¹æ³•ï¼Œæœ€åè°ƒç”¨ `handler()` æ–¹æ³•ï¼Œ è¿™æ ·æ‚¨å°±å¯ä»¥åªæ¶ˆè´¹ç‰¹å®šåˆ†åŒºçš„æŒ‡å®šåç§»ä¹‹åçš„æ¶ˆæ¯ã€‚

è°ƒç”¨ `assignment` å¯ä»¥è®©æ‚¨ è·å–å½“å‰åˆ†é…çš„æ¶ˆæ¯åˆ†åŒºã€‚

## é€šè¿‡æ˜¾å¼è¯·æ±‚è·å–æ¶ˆæ¯

ä¸ºäº†ä» Kafka æ¥æ”¶æ¶ˆæ¯ï¼Œé™¤äº†ä½¿ç”¨å®¢æˆ·ç«¯å†…éƒ¨è‡ªå¸¦çš„è¯·æ±‚æœºåˆ¶å¤–ï¼Œ å®¢æˆ·ç«¯å¯ä»¥è®¢é˜… ä¸»é¢˜ï¼Œ å¹¶ä¸”ä¸æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨ï¼Œå¹¶ä½¿ç”¨ `poll` æ–¹æ³•è·å–æ¶ˆæ¯ã€‚

é€šè¿‡è¿™ç§æ–¹å¼ï¼Œ ç”¨æˆ·çš„åº”ç”¨å¯ä»¥åœ¨å…¶éœ€è¦æ—¶æ‰æ‰§è¡Œè¯·æ±‚ä»¥è·å–æ¶ˆæ¯ï¼Œ ä¸¾ä¸ªä¾‹å­ã€‚

```java
consumer
  .subscribe("test")
  .onSuccess(v -> {
    System.out.println("Consumer subscribed");

    // æ¯ç§’è¯·æ±‚ä¸€æ¬¡
    vertx.setPeriodic(1000, timerId ->
      consumer
        .poll(Duration.ofMillis(100))
        .onSuccess(records -> {
          for (int i = 0; i < records.size(); i++) {
            KafkaConsumerRecord<String, String> record = records.recordAt(i);
            System.out.println("key=" + record.key() + ",value=" + record.value() +
              ",partition=" + record.partition() + ",offset=" + record.offset());
          }
        })
        .onFailure(cause -> {
          System.out.println("Something went wrong when polling " + cause.toString());
          cause.printStackTrace();

          // å½“å‘ç”Ÿé”™è¯¯æ—¶åœæ­¢è¯·æ±‚
          vertx.cancelTimer(timerId);
        })
    );
});
```

è®¢é˜…æˆåŠŸåï¼Œ åº”ç”¨å¯åŠ¨äº†ä¸€ä¸ªå®šæ—¶å™¨æ¥æ‰§è¡Œè¯·æ±‚å¹¶ä¸” å‘¨æœŸæ€§åœ°ä» kafka è·å–æ¶ˆæ¯ã€‚

## æ”¹å˜è®¢é˜…æˆ–ä¸»é¢˜åˆ†åŒºçš„åˆ†é…

æ‚¨å¯ä»¥åœ¨å¼€å§‹æ¶ˆè´¹æ¶ˆæ¯ä¹‹åä¿®æ”¹è®¢é˜…çš„ä¸»é¢˜æˆ–ä¸»é¢˜åˆ†åŒºçš„åˆ†é…ï¼Œåªéœ€è¦ é‡æ–°è°ƒç”¨ `subscribe()` æ–¹æ³•æˆ– `assign()` æ–¹æ³•ã€‚

è¯·è®°ä½ï¼Œç”±äº kafka å®¢æˆ·ç«¯çš„å†…éƒ¨å­˜åœ¨æ¶ˆæ¯ç¼“å­˜ï¼Œ å› æ­¤å¾ˆæœ‰å¯èƒ½åœ¨æ‚¨ è°ƒç”¨ `subscribe()` æ–¹æ³•æˆ– `assign()` æ–¹æ³• *ä¹‹å* ï¼ŒåŸå…ˆçš„æ¶ˆæ¯å¤„ç†å™¨ä»ç„¶ æ”¶åˆ°äº†æ—§çš„ä¸»é¢˜æˆ–åˆ†åŒºçš„æ¶ˆæ¯ã€‚ ä½†æ˜¯å¦‚æœæ‚¨ä½¿ç”¨äº†æ‰¹å¤„ç†å™¨å°±ä¸ä¼šå‘ç”Ÿè¿™ç§æƒ…å†µï¼š ä¸€æ—¦é‡æ–°è°ƒç”¨è®¢é˜…æˆ–ä¿®æ”¹æ–¹æ³•çš„å®Œæˆå›è°ƒè¢«è§¦å‘ï¼Œ é‚£ä¹ˆå®¢æˆ·ç«¯å°±åªä¼šæ”¶åˆ°æ–°çš„ä¸»é¢˜æˆ–åˆ†åŒºçš„æ¶ˆæ¯ã€‚

## è·å–ä¸»é¢˜åˆ†åŒºä¿¡æ¯

æ‚¨å¯ä»¥è°ƒç”¨ `partitionsFor` æ–¹æ³•æ¥è·å– ç‰¹å®šä¸»é¢˜çš„åˆ†åŒºä¿¡æ¯ã€‚

```java
consumer
  .partitionsFor("test")
  .onSuccess(partitions -> {
    for (PartitionInfo partitionInfo : partitions) {
      System.out.println(partitionInfo);
    }
  });
```

æ‚¨ä¹Ÿå¯ä»¥è°ƒç”¨ `listTopics` æ–¹æ³•è·å–æ‰€æœ‰å½“å‰ä¸»é¢˜çš„ åˆ†åŒºä¿¡æ¯ã€‚

```java
consumer
  .listTopics()
  .onSuccess(partitionsTopicMap ->
    partitionsTopicMap.forEach((topic, partitions) -> {
      System.out.println("topic = " + topic);
      System.out.println("partitions = " + partitions);
    })
  );
```

## æ‰‹åŠ¨æäº¤åç§»

Apache Kafka çš„æ¶ˆè´¹è€…ä¸€èˆ¬ä¼šå¤„ç†æœ€åä¸€ä¸ªè¯»å–çš„æ¶ˆæ¯çš„åç§»ã€‚

ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œkafka çš„å®¢æˆ·ç«¯ä¼šè‡ªåŠ¨åœ°åœ¨æ¯æ¬¡ä»ä¸»é¢˜åˆ†åŒºè·å–ä¸€æ‰¹æ¶ˆæ¯ åé€šè¿‡æäº¤æ“ä½œå¤„ç†ã€‚ é…ç½®å‚æ•° `enable.auto.commit` ä¼šåœ¨å®¢æˆ·ç«¯è¢«åˆ›å»ºæ—¶è®¾ç½® ä¸º `true` ã€‚

æ‰‹åŠ¨æäº¤åç§»ï¼Œå¯ä»¥ä½¿ç”¨ `commit` æ–¹æ³•ã€‚ è¿™æ ·å¯ä»¥ç¡®ä¿ *è‡³å°‘ä¸€æ¬¡* æäº¤åç§»å‰æ¶ˆæ¯å·²ç»è¢« å¤„ç†äº†ã€‚

```java
consumer.commit().onSuccess(v ->
  System.out.println("Last read message offset committed")
);
```

## åœ¨æ¶ˆæ¯åˆ†åŒºå†…æŸ¥è¯¢

Apache Kafka å¯ä»¥ä¿å­˜ä¸€æ®µæ—¶é—´å†…çš„æ¶ˆæ¯æ•°æ®ï¼Œå¹¶ä¸”æ¶ˆè´¹è€…å¯ä»¥åœ¨æ¶ˆæ¯åˆ†åŒºå†…æŸ¥è¯¢ å¹¶è·å–ä»»æ„ä¸€æ¡æ¶ˆæ¯ã€‚

æ‚¨å¯ä»¥ä½¿ç”¨ `seek` æ–¹æ³•æ¥æ”¹å˜è¯»å–æ—¶çš„åç§»ï¼Œå¹¶ç§»åŠ¨åˆ° ç‰¹å®šçš„ä½ç½®

```java
TopicPartition topicPartition = new TopicPartition()
  .setTopic("test")
  .setPartition(0);

// ç§»åŠ¨ç‰¹å®šçš„åç§»
consumer
  .seek(topicPartition, 10)
  .onSuccess(v -> System.out.println("Seeking done"));
```

å½“æ¶ˆè´¹è€…éœ€è¦ä»å¼€å§‹å¤„é‡æ–°è·å–æ¶ˆæ¯æ—¶ï¼Œå¯ä»¥ä½¿ç”¨ `seekToBeginning`

```java
TopicPartition topicPartition = new TopicPartition()
  .setTopic("test")
  .setPartition(0);

// ç§»åŠ¨åç§»åˆ°åˆ†åŒºå¼€å¤´
consumer
  .seekToBeginning(Collections.singleton(topicPartition))
  .onSuccess(v -> System.out.println("Seeking done"));
```

æœ€åï¼Œ`seekToEnd` å¯ä»¥ç”¨äºå°†åç§»ç§»åŠ¨åˆ°åˆ†åŒºçš„ç»“å°¾

```java
TopicPartition topicPartition = new TopicPartition()
  .setTopic("test")
  .setPartition(0);

// ç§»åŠ¨åç§»åˆ°åˆ†åŒºæœ«å°¾
consumer
  .seekToEnd(Collections.singleton(topicPartition))
  .onSuccess(v -> System.out.println("Seeking done"));
```

è¯·è®°ä½ï¼Œç”±äº kafka å®¢æˆ·ç«¯çš„å†…éƒ¨å­˜åœ¨æ¶ˆæ¯ç¼“å­˜ï¼Œ å› æ­¤å¾ˆæœ‰å¯èƒ½åœ¨æ‚¨ è°ƒç”¨å®Œ `seek*()` æ–¹æ³• *ä¹‹å* åŸæœ‰çš„æ¶ˆæ¯å¤„ç†å™¨ä»åœ¨è·å–åŸå…ˆ åç§»å¤„çš„æ¶ˆæ¯ã€‚ ä½†æ˜¯å¦‚æœæ‚¨ä½¿ç”¨äº†æ‰¹å¤„ç†å™¨å°±ä¸ä¼šå‘ç”Ÿè¿™ç§æƒ…å†µï¼š ä¸€æ—¦ `seek*()` çš„å®Œæˆå›è°ƒè¢«è§¦å‘ï¼Œ æ¶ˆæ¯å¤„ç†å™¨å°±åªä¼šæ¥æ”¶åˆ°æ–°çš„åç§»å¤„çš„æ¶ˆæ¯ã€‚

## æŸ¥è¯¢åç§»

æ‚¨å¯ä»¥ä½¿ç”¨åœ¨ Kafka 0.10.1.1 å¼•å…¥çš„ beginningOffsets æ¥å£æ¥è·å–æŒ‡å®šåˆ†åŒºçš„ ç¬¬ä¸€ä¸ªåç§»ã€‚ ä¸ `seekToBeginning` æ–¹æ³•ä¸åŒçš„æ˜¯ï¼Œ è¯¥æ¥å£å¹¶ä¸ä¼šæ”¹å˜å½“å‰å®¢æˆ·ç«¯çš„åç§»ã€‚

```java
Set<TopicPartition> topicPartitions = new HashSet<>();
TopicPartition topicPartition = new TopicPartition().setTopic("test").setPartition(0);
topicPartitions.add(topicPartition);

consumer
  .beginningOffsets(topicPartitions)
  .onSuccess(results ->
    results.forEach((topic, beginningOffset) ->
      System.out.println(
        "Beginning offset for topic=" + topic.getTopic() + ", partition=" +
          topic.getPartition() + ", beginningOffset=" + beginningOffset
      )
    )
  );

// æ–¹ä¾¿åœ°è·å–ä¸€ä¸ªåˆ†åŒºçš„åç§»
consumer
  .beginningOffsets(topicPartition)
  .onSuccess(beginningOffset ->
    System.out.println(
      "Beginning offset for topic=" + topicPartition.getTopic() + ", partition=" +
        topicPartition.getPartition() + ", beginningOffset=" + beginningOffset
    )
  );
```

æ‚¨å¯ä»¥ä½¿ç”¨åœ¨ Kafka 0.10.1.1 å¼•å…¥çš„ endOffsets æ¥å£æ¥è·å–æŒ‡å®šåˆ†åŒºçš„ ç»“å°¾åç§»ã€‚ ä¸ `seekToEnd` æ–¹æ³•ä¸åŒçš„æ˜¯ï¼Œ è¯¥æ¥å£å¹¶ä¸ä¼šæ”¹å˜å½“å‰å®¢æˆ·ç«¯çš„åç§»ã€‚

```java
Set<TopicPartition> topicPartitions = new HashSet<>();
TopicPartition topicPartition = new TopicPartition().setTopic("test").setPartition(0);
topicPartitions.add(topicPartition);

consumer.endOffsets(topicPartitions)
  .onSuccess(results ->
    results.forEach((topic, beginningOffset) ->
      System.out.println(
        "End offset for topic=" + topic.getTopic() + ", partition=" +
          topic.getPartition() + ", beginningOffset=" + beginningOffset
      )
    )
  );

// æ–¹ä¾¿åœ°è·å–ä¸€ä¸ªåˆ†åŒºçš„åç§»
consumer
  .endOffsets(topicPartition)
  .onSuccess(endOffset ->
    System.out.println(
      "End offset for topic=" + topicPartition.getTopic() + ", partition=" +
        topicPartition.getPartition() + ", endOffset=" + endOffset
    )
);
```

æ‚¨å¯ä»¥ä½¿ç”¨åœ¨ Kafka 0.10.1.1 å¼•å…¥çš„ endOffsets æ¥å£æ¥æ ¹æ®æ—¶é—´æˆ³è·å–æŒ‡å®šåˆ†åŒºçš„ åç§»ã€‚æŸ¥è¯¢å‚æ•°æ˜¯ä¸€ä¸ª unix æ—¶é—´æˆ³ï¼Œè€Œè¿”å›çš„ç»“æœæ˜¯æ»¡è¶³ æ‘„å…¥æ—¶é—´ >= ç»™å®šæ—¶é—´æ¡ä»¶çš„æœ€å°åç§»ã€‚

```java
Map<TopicPartition, Long> topicPartitionsWithTimestamps = new HashMap<>();
TopicPartition topicPartition = new TopicPartition().setTopic("test").setPartition(0);

// æˆ‘ä»¬æƒ³çŸ¥é“ 60 ç§’å‰æ‘„å…¥æ¶ˆæ¯çš„åç§»
long timestamp = (System.currentTimeMillis() - 60000);

topicPartitionsWithTimestamps.put(topicPartition, timestamp);
consumer
  .offsetsForTimes(topicPartitionsWithTimestamps)
  .onSuccess(results ->
    results.forEach((topic, offset) ->
      System.out.println(
        "Offset for topic=" + topic.getTopic() +
        ", partition=" + topic.getPartition() + "\n" +
        ", timestamp=" + timestamp + ", offset=" + offset.getOffset() +
        ", offsetTimestamp=" + offset.getTimestamp()
      )
    )
);

// æ–¹ä¾¿åœ°è·å–ä¸€ä¸ªåˆ†åŒºçš„åç§»
consumer.offsetsForTimes(topicPartition, timestamp).onSuccess(offsetAndTimestamp ->
  System.out.println(
    "Offset for topic=" + topicPartition.getTopic() +
    ", partition=" + topicPartition.getPartition() + "\n" +
    ", timestamp=" + timestamp + ", offset=" + offsetAndTimestamp.getOffset() +
    ", offsetTimestamp=" + offsetAndTimestamp.getTimestamp()
  )
);
```

## æ¶ˆæ¯æµæ§åˆ¶

kafka çš„æ¶ˆè´¹è€…å¯ä»¥æ§åˆ¶æ¶ˆæ¯çš„æµå…¥ï¼Œå¹¶ä¸”æš‚åœ / é‡å¯ä»ä¸€ä¸ªä¸»é¢˜ä¸­è¯»å–æ¶ˆæ¯çš„æ“ä½œã€‚å½“æ¶ˆè´¹è€…éœ€è¦ æ›´å¤šæ—¶é—´å»å¤„ç†å½“å‰æ¶ˆæ¯æ—¶ï¼Œå®ƒå¯ä»¥æš‚åœæ¶ˆæ¯æµï¼Œå®ƒä¹Ÿå¯ä»¥é‡å¯æ¶ˆæ¯æµ å»ç»§ç»­å¤„ç†æ¶ˆæ¯ã€‚

ä¸ºäº†è¿™ä¹ˆåšï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ `pause` æ–¹æ³•å’Œ `resume` æ–¹æ³•ã€‚

åœ¨å¯¹ç‰¹å®šçš„ä¸»é¢˜åˆ†åŒºè°ƒç”¨äº†æš‚åœå’Œé‡å¯æ–¹æ³•åï¼Œæ¶ˆæ¯å¤„ç†å™¨æœ‰å¯èƒ½ä»ç„¶ä¼šä» å·²ç»æš‚åœäº†çš„ä¸»é¢˜åˆ†åŒºæ¥æ”¶æ¶ˆæ¯ï¼Œå³ä½¿æ˜¯åœ¨ `pause()` æ–¹æ³•çš„å®Œæˆå›è°ƒ *å·²ç»è¢«è°ƒç”¨ä¹‹å* ã€‚ å¦‚æœæ‚¨ä½¿ç”¨äº†æ‰¹å¤„ç†å™¨ï¼Œä¸€æ—¦æ‚¨è°ƒç”¨ `pause()` æ–¹æ³•çš„å®Œæˆå›è°ƒè¢«è°ƒç”¨ï¼Œ æ¶ˆè´¹è€…å°±åªèƒ½ä»æœªè¢«æš‚åœçš„ä¸»é¢˜åˆ†åŒº æ¥æ”¶æ¶ˆæ¯ã€‚

```java
TopicPartition topicPartition = new TopicPartition()
  .setTopic("test")
  .setPartition(0);

// æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨
consumer.handler(record -> {
  System.out.println("key=" + record.key() + ",value=" + record.value() +
    ",partition=" + record.partition() + ",offset=" + record.offset());

  // åœ¨æ¥æ”¶æ¶ˆæ¯çš„åç§»åˆ°è¾¾ 5 ä¹‹åæš‚åœ / é‡å¯åˆ†åŒº 0 çš„æ¶ˆæ¯æµ
  if ((record.partition() == 0) && (record.offset() == 5)) {

    // pause the read operations
    consumer.pause(topicPartition)
      .onSuccess(v -> System.out.println("Paused"))
      .onSuccess(v -> vertx.setTimer(5000, timeId ->
        // é‡å¯è¯»æ“ä½œ
        consumer.resume(topicPartition)
      ));
  }
});
```

## å…³é—­æ¶ˆè´¹è€…

è°ƒç”¨ close æ–¹æ³•æ¥å…³é—­æ¶ˆè´¹è€…ã€‚ å…³é—­æ¶ˆè´¹è€…ä¼šå…³é—­å…¶æ‰€æŒæœ‰çš„æ‰€æœ‰è¿æ¥å¹¶é‡Šæ”¾å®ƒæ‰€æœ‰çš„æ¶ˆè´¹è€…èµ„æºã€‚

close æ–¹æ³•æ˜¯å¼‚æ­¥çš„å¹¶ä¸”åœ¨æ–¹æ³•è¿”å›æ—¶å¯èƒ½è¿˜æœªå®Œæˆã€‚ å¦‚æœæ‚¨æƒ³åœ¨å…³é—­å®Œæˆå æ”¶åˆ°é€šçŸ¥ï¼Œé‚£ä¹ˆå¯ä»¥å‘å…¶ä¼ é€’ä¸€ä¸ªå›è°ƒå¤„ç†å™¨ã€‚

è¯¥å›è°ƒå¤„ç†å™¨ä¼šåœ¨å…³é—­æ“ä½œå®Œå…¨å®Œæˆåè¢«è°ƒç”¨ã€‚

```java
consumer
  .close()
  .onSuccess(v -> System.out.println("Consumer is now closed"))
  .onFailure(cause -> System.out.println("Close failed: " + cause));
```

## å‘ä¸»é¢˜å‘é€æ¶ˆæ¯

æ‚¨å¯ä»¥ä½¿ç”¨ `write` æ–¹æ³•å»å‘é€æ¶ˆæ¯ (è®°å½•) ç»™ä¸»é¢˜ã€‚

æœ€ç®€å•çš„å‘é€æ¶ˆæ¯çš„æ–¹æ³•æ˜¯æŒ‡å®šç›®æ ‡ä¸»é¢˜å’Œç›¸å¯¹åº”çš„å€¼ï¼Œ å¿½ç•¥å®ƒçš„é”® å’Œåˆ†åŒºï¼Œè¿™ç§æƒ…å†µä¸‹æ¶ˆæ¯ä¼šä»¥è½®æµå¾ªç¯çš„æ–¹å¼å‘—å‘é€ç»™è¯¥ä¸»é¢˜çš„æ‰€æœ‰åˆ†åŒºã€‚

```java
for (int i = 0; i < 5; i++) {

  // åªè®¾ç½®ä¸»é¢˜å’Œæ¶ˆæ¯å†…å®¹çš„æƒ…å†µä¸‹ï¼Œæ¶ˆæ¯ä¼šè¢«å¾ªç¯è½®æµå‘é€ç»™ç›®çš„ä¸»é¢˜çš„æ‰€æœ‰åˆ†åŒº
  KafkaProducerRecord<String, String> record =
    KafkaProducerRecord.create("test", "message_" + i);

  producer.write(record);
}
```

åœ¨å‘é€æ¶ˆæ¯æˆåŠŸæ—¶ï¼Œæ‚¨å¯ä»¥æ¥æ”¶åˆ°è¯¥æ¶ˆæ¯åœ¨ kafka ä¸­çš„å…ƒæ•°æ®ï¼Œä¾‹å¦‚å®ƒçš„ä¸»é¢˜ï¼Œç›®æ ‡åˆ†åŒºå’Œå®ƒåœ¨å­˜å‚¨ä¸­çš„åç§»ã€‚

```java
for (int i = 0; i < 5; i++) {

  // åªè®¾ç½®ä¸»é¢˜å’Œæ¶ˆæ¯å†…å®¹çš„æƒ…å†µä¸‹ï¼Œæ¶ˆæ¯ä¼šè¢«å¾ªç¯è½®æµå‘é€ç»™ç›®çš„ä¸»é¢˜çš„æ‰€æœ‰åˆ†åŒº
  KafkaProducerRecord<String, String> record =
    KafkaProducerRecord.create("test", "message_" + i);

  producer.send(record).onSuccess(recordMetadata ->
    System.out.println(
      "Message " + record.value() + " written on topic=" + recordMetadata.getTopic() +
      ", partition=" + recordMetadata.getPartition() +
      ", offset=" + recordMetadata.getOffset()
    )
  );
}
```

å½“æ‚¨éœ€è¦æŒ‡å®šæ¶ˆæ¯å‘é€çš„åˆ†åŒºæ—¶ï¼Œæ‚¨éœ€è¦æŒ‡å®šå®ƒçš„åˆ†åŒºæ ‡è¯†ç¬¦æˆ– æ¶ˆæ¯çš„é”®ã€‚

```java
for (int i = 0; i < 10; i++) {

  // æŒ‡å®šåˆ†åŒº
  KafkaProducerRecord<String, String> record =
    KafkaProducerRecord.create("test", null, "message_" + i, 0);

  producer.write(record);
}
```

ç”±äºæ¶ˆæ¯çš„ç”Ÿäº§è€…ä½¿ç”¨é”®çš„å“ˆå¸Œè®¡ç®—å¯¹åº”çš„ä¸»é¢˜åˆ†åŒºï¼Œæ‚¨å¯ä»¥åˆ©ç”¨è¿™ä¸€ç‚¹ä¿è¯æ‹¥æœ‰ç›¸åŒé”®çš„æ‰€æœ‰ æ¶ˆæ¯éƒ½æŒ‰ç…§é¡ºåºè¢«å‘é€ç»™ä¸€ä¸ªç›¸åŒçš„åˆ†åŒºã€‚

```java
for (int i = 0; i < 10; i++) {

  // æ ¹æ®å¥‡å¶æ€§è®¾ç½®æ¶ˆæ¯çš„é”®
  int key = i % 2;

  // æŒ‡å®šä¸€ä¸ªæ¶ˆæ¯çš„é”®ï¼Œæ‰€æœ‰é”®ç›¸åŒçš„æ¶ˆæ¯ä¼šè¢«å‘ç»™åŒä¸€ä¸ªåˆ†åŒº
  KafkaProducerRecord<String, String> record =
    KafkaProducerRecord.create("test", String.valueOf(key), "message_" + i);

  producer.write(record);
}
```

> <mark>**è¯·è®°ä½:**</mark>å¯å…±ç”¨çš„ç”Ÿäº§è€…é€šè¿‡ `createShared` æ–¹æ³•çš„ç¬¬ä¸€æ¬¡è°ƒç”¨åˆ›å»ºï¼Œå¹¶ä¸”å®ƒçš„é…ç½®åœ¨æ­¤æ—¶è¢«è®¾ç½®ï¼Œ å¯å…±ç”¨çš„ç”Ÿäº§è€…ä½¿ç”¨æ—¶å¿…é¡»ç¡®ä¿é…ç½®ç›¸åŒã€‚

## å…¬ç”¨ç”Ÿäº§è€…

æœ‰æ—¶æ‚¨éœ€è¦åœ¨å¤šä¸ª verticle æˆ–ä¸Šä¸‹æ–‡ï¼ˆcontextï¼‰ä¸­å…±äº«åŒä¸€ä¸ªç”Ÿäº§è€…ã€‚

ä½¿ç”¨ `KafkaProducer.createShared` æ–¹æ³• è¿”å›ä¸€ä¸ªå¯ä»¥è¢«å®‰å…¨åœ°å…±ç”¨çš„ producerã€‚

```java
KafkaProducer<String, String> producer1 = KafkaProducer.createShared(vertx, "the-producer", config);

// ä¹‹åæ‚¨å¯ä»¥å…³é—­å®ƒ
producer1.close();
```

é€šè¿‡è¯¥æ–¹æ³•è¿”å›çš„ç”Ÿäº§è€…ä¼šå…±äº«ç›¸åŒçš„èµ„æºï¼ˆçº¿ç¨‹ï¼Œè¿æ¥ï¼‰ ã€‚

å½“æ‚¨ä½¿ç”¨å®Œæ¯•è¯¥ç”Ÿäº§è€…åï¼Œå¯ä»¥ç®€å•åœ°å…³é—­å®ƒã€‚ å½“æ‰€æœ‰å…±ç”¨çš„ç”Ÿäº§è€…è¢«å…³é—­åï¼Œæ‰€æœ‰çš„èµ„æº ä¹Ÿä¼šè¢«é‡Šæ”¾ã€‚

## å…³é—­ç”Ÿäº§è€…

è°ƒç”¨ close æ–¹æ³•æ¥å…³é—­ç”Ÿäº§è€…ã€‚å…³é—­ç”Ÿäº§è€…ä¼šå…³é—­å…¶æ‰“å¼€çš„è¿æ¥å¹¶é‡Šæ”¾å…¶æ‰€å æœ‰çš„æ‰€æœ‰èµ„æºã€‚

å…³é—­æ˜¯å¼‚æ­¥è¿›è¡Œçš„ï¼Œå› æ­¤åœ¨è°ƒç”¨è¿”å›æ—¶ç”Ÿäº§è€…å¯èƒ½è¿˜æ²¡æœ‰å®Œå…¨å…³é—­ã€‚ å¦‚æœæ‚¨æƒ³åœ¨ å…³é—­å®Œæˆæ—¶æ”¶åˆ°é€šçŸ¥ï¼Œé‚£ä¹ˆæ‚¨å¯ä»¥ä¼ å…¥ä¸€ä¸ªå›è°ƒã€‚

è¿™ä¸ªå›è°ƒä¼šåœ¨ç”Ÿäº§è€…è¢«å®Œå…¨å…³é—­åè°ƒç”¨ã€‚

```java
producer
  .close()
  .onSuccess(v -> System.out.println("Producer is now closed"))
  .onFailure(cause -> System.out.println("Close failed: " + cause));
```

## è·å–ä¸»é¢˜åˆ†ç‰‡ä¿¡æ¯

æ‚¨å¯ä»¥è°ƒç”¨ `partitionsFor` æ–¹æ³•æ¥è·å– æŒ‡å®šä¸»é¢˜çš„åˆ†ç‰‡ä¿¡æ¯ï¼š

```java
producer
  .partitionsFor("test")
  .onSuccess(partitions ->
    partitions.forEach(System.out::println)
  );
```

## å¤„ç†é”™è¯¯

kafka å®¢æˆ·ç«¯ï¼ˆæ¶ˆè´¹è€…æˆ–ç”Ÿäº§è€…ï¼‰å’Œ kafka é›†ç¾¤é—´çš„å¼‚å¸¸å¤„ç† (ä¾‹å¦‚è¿æ¥è¶…æ—¶) éœ€è¦ç”¨åˆ° `exceptionHandler` æ–¹æ³•æˆ– `exceptionHandler` æ–¹æ³•

```java
consumer.exceptionHandler(e -> {
  System.out.println("Error = " + e.getMessage());
});
```

## verticle çš„è‡ªåŠ¨æ¸…ç†

å¦‚æœæ‚¨æ˜¯åœ¨ verticle ä¸­åˆ›å»º kafka çš„æ¶ˆè´¹è€…å’Œç”Ÿäº§è€…çš„ï¼Œé‚£ä¹ˆè¿™äº›æ¶ˆè´¹è€…å’Œç”Ÿäº§è€…ä¼šåœ¨ è¯¥ verticle è¢«å–æ¶ˆéƒ¨ç½²æ—¶è¢«è‡ªåŠ¨æ¸…ç†ã€‚

## ä½¿ç”¨ Vert.x çš„åºåˆ—åŒ–å™¨ / ååºåˆ—åŒ–å™¨

Vert.x çš„ Kafka å®¢æˆ·ç«¯çš„å®ç°è‡ªå¸¦äº†å¯¹ Buffer æ•°æ®ç±»å‹ï¼Œ json å¯¹è±¡ å’Œ json å¯¹è±¡æ•°ç»„çš„åºåˆ—åŒ–å™¨å’Œååºåˆ—åŒ–å™¨çš„åŒ…è£…ã€‚

ä½¿ç”¨æ¶ˆè´¹è€…æ—¶æ‚¨å¯ä»¥ç›´æ¥æ¥æ”¶ Buffer æ•°æ®ç±»å‹

```java
Map<String, String> config = new HashMap<>();
config.put("bootstrap.servers", "localhost:9092");
config.put("key.deserializer", "io.vertx.kafka.client.serialization.BufferDeserializer");
config.put("value.deserializer", "io.vertx.kafka.client.serialization.BufferDeserializer");
config.put("group.id", "my_group");
config.put("auto.offset.reset", "earliest");
config.put("enable.auto.commit", "false");

// åˆ›å»ºä¸€ä¸ªå¯ä»¥ååºåˆ—åŒ– json å¯¹è±¡çš„æ¶ˆè´¹è€…
config = new HashMap<>();
config.put("bootstrap.servers", "localhost:9092");
config.put("key.deserializer", "io.vertx.kafka.client.serialization.JsonObjectDeserializer");
config.put("value.deserializer", "io.vertx.kafka.client.serialization.JsonObjectDeserializer");
config.put("group.id", "my_group");
config.put("auto.offset.reset", "earliest");
config.put("enable.auto.commit", "false");

// åˆ›å»ºä¸€ä¸ªå¯ä»¥ååºåˆ—åŒ– json å¯¹è±¡æ•°ç»„çš„æ¶ˆè´¹è€…
config = new HashMap<>();
config.put("bootstrap.servers", "localhost:9092");
config.put("key.deserializer", "io.vertx.kafka.client.serialization.JsonArrayDeserializer");
config.put("value.deserializer", "io.vertx.kafka.client.serialization.JsonArrayDeserializer");
config.put("group.id", "my_group");
config.put("auto.offset.reset", "earliest");
config.put("enable.auto.commit", "false");
```

åœ¨ç”Ÿäº§è€…ç«¯ï¼Œæ‚¨ä¹Ÿå¯ä»¥è¿™ä¹ˆåš

```java
Map<String, String> config = new HashMap<>();
config.put("bootstrap.servers", "localhost:9092");
config.put("key.serializer", "io.vertx.kafka.client.serialization.BufferSerializer");
config.put("value.serializer", "io.vertx.kafka.client.serialization.BufferSerializer");
config.put("acks", "1");

// åˆ›å»ºä¸€ä¸ªå¯ä»¥åºåˆ—åŒ– json å¯¹è±¡çš„ç”Ÿäº§è€…
config = new HashMap<>();
config.put("bootstrap.servers", "localhost:9092");
config.put("key.serializer", "io.vertx.kafka.client.serialization.JsonObjectSerializer");
config.put("value.serializer", "io.vertx.kafka.client.serialization.JsonObjectSerializer");
config.put("acks", "1");

// åˆ›å»ºä¸€ä¸ªå¯ä»¥åºåˆ—åŒ– json å¯¹è±¡æ•°ç»„çš„ç”Ÿäº§è€…
config = new HashMap<>();
config.put("bootstrap.servers", "localhost:9092");
config.put("key.serializer", "io.vertx.kafka.client.serialization.JsonArraySerializer");
config.put("value.serializer", "io.vertx.kafka.client.serialization.JsonArraySerializer");
config.put("acks", "1");
```

æ‚¨å¯ä»¥åœ¨åˆ›å»ºæ—¶ç›´æ¥æŒ‡å®šåºåˆ—åŒ–å™¨/ååºåˆ—åŒ–å™¨ï¼š

å¯¹äºæ¶ˆè´¹è€…

```java
Map<String, String> config = new HashMap<>();
config.put("bootstrap.servers", "localhost:9092");
config.put("group.id", "my_group");
config.put("auto.offset.reset", "earliest");
config.put("enable.auto.commit", "false");

// åˆ›å»ºä¸€ä¸ªå¯ä»¥ååºåˆ—åŒ– Buffer æ•°æ®ç±»å‹çš„æ¶ˆè´¹è€…
KafkaConsumer<Buffer, Buffer> bufferConsumer = KafkaConsumer.create(vertx, config, Buffer.class, Buffer.class);

// åˆ›å»ºä¸€ä¸ªå¯ä»¥ååºåˆ—åŒ– json å¯¹è±¡çš„æ¶ˆè´¹è€…
KafkaConsumer<JsonObject, JsonObject> jsonObjectConsumer = KafkaConsumer.create(vertx, config, JsonObject.class, JsonObject.class);

// åˆ›å»ºä¸€ä¸ªå¯ä»¥ååºåˆ—åŒ– json å¯¹è±¡æ•°ç»„çš„æ¶ˆè´¹è€…
KafkaConsumer<JsonArray, JsonArray> jsonArrayConsumer = KafkaConsumer.create(vertx, config, JsonArray.class, JsonArray.class);
```

è€Œå¯¹äºç”Ÿäº§è€…

```java
Map<String, String> config = new HashMap<>();
config.put("bootstrap.servers", "localhost:9092");
config.put("acks", "1");

// åˆ›å»ºä¸€ä¸ªå¯ä»¥åºåˆ—åŒ– Buffer æ•°æ®ç±»å‹çš„ç”Ÿäº§è€…
KafkaProducer<Buffer, Buffer> bufferProducer = KafkaProducer.create(vertx, config, Buffer.class, Buffer.class);

// åˆ›å»ºä¸€ä¸ªå¯ä»¥åºåˆ—åŒ– json å¯¹è±¡çš„ç”Ÿäº§è€…
KafkaProducer<JsonObject, JsonObject> jsonObjectProducer = KafkaProducer.create(vertx, config, JsonObject.class, JsonObject.class);

// åˆ›å»ºä¸€ä¸ªå¯ä»¥åºåˆ—åŒ– json å¯¹è±¡æ•°ç»„çš„ç”Ÿäº§è€…
KafkaProducer<JsonArray, JsonArray> jsonArrayProducer = KafkaProducer.create(vertx, config, JsonArray.class, JsonArray.class);
```

## RxJava 3 æ¥å£

Kafka å®¢æˆ·ç«¯æä¾›äº†åœ¨åŸæœ‰ API åŸºç¡€ä¸Šçš„å“åº”å¼æ¥å£

```java
Observable<KafkaConsumerRecord<String, Long>> observable = consumer.toObservable();

observable
  .map(record -> record.value())
  .buffer(256)
  .map(
  list -> list.stream().mapToDouble(n -> n).average()
).subscribe(val -> {

  // è·å–å¹³å‡å€¼

});
```

## è‡ªåŠ¨è¿½è¸ªä¼ æ’­

å½“æ‚¨é…ç½® Vert.x å¼€å¯è¿½è¸ªæ—¶ (å‚è§ `setTracingOptions`)ï¼Œ è¿½è¸ªå¯ä»¥é€šè¿‡ Kafka çš„æ¶ˆæ¯è‡ªåŠ¨ä¼ æ’­ã€‚

Kafka çš„ç”Ÿäº§è€…ä¼šåœ¨å†™å…¥æ¶ˆæ¯æ—¶è‡ªåŠ¨æ·»åŠ ä¸€ä¸ª Span å»è¿½è¸ªï¼Œè¿½è¸ªçš„ä¸Šä¸‹æ–‡é€šè¿‡ Kafka æ¶ˆæ¯å¤´éƒ¨ä¼ é€’ã€‚å¹¶ä¸”æ¶ˆè´¹è€…ä¼šåœ¨æ”¶åˆ°æ¶ˆæ¯åæ ¹æ®æ¶ˆæ¯å¤´éƒ¨ä¿¡æ¯é‡å»º Spanã€‚

å‚è€ƒä»¥ä¸‹ä¿¡æ¯ [OpenTracing semantic convention](https://github.com/opentracing/specification/blob/master/semantic_conventions.md), Span çš„æ ‡ç­¾åŒ…æ‹¬ï¼š

- `span.kind`ï¼Œç±»å‹æ˜¯ `consumer` æˆ– `producer`
- `peer.address` å¯ä»¥ä½¿ç”¨ `setTracePeerAddress` é…ç½®ã€‚å¦‚æœæ²¡æœ‰è®¾ç½®ï¼Œé‚£ä¹ˆä¼šä½¿ç”¨é…ç½®ä¸­çš„ Kafka æœåŠ¡å™¨åœ°å€
- `peer.hostname` é€šè¿‡è§£æ `peer.address` å¾—åˆ°
- `peer.port` é€šè¿‡è§£æ `peer.address` å¾—åˆ°
- `peer.service` ä¸€ç›´æ˜¯ always `kafka`
- `message_bus.destination`, ä¼šè®¾ç½®ä¸º kafka æ¶ˆæ¯çš„ä¸»é¢˜

# Vert.x Kafka ç®¡ç†å®¢æˆ·ç«¯

è¯¥ç»„ä»¶æä¾›äº†å¯¹ Kafka ç®¡ç†å®¢æˆ·ç«¯æ¥å£çš„ Vert.x é£æ ¼çš„åŒ…è£…ã€‚ Kafka ç®¡ç†å®¢æˆ·ç«¯ç”¨äºåˆ›å»ºï¼Œä¿®æ”¹å’Œåˆ é™¤ä¸»é¢˜ã€‚ é™¤æ­¤ä¹‹å¤–ï¼Œå®ƒè¿˜å¯ä»¥ç”¨äºç®¡ç† ACL (Access Control Lists)ï¼Œæ¶ˆè´¹è€…ç¾¤ç»„å’Œæ›´å¤šä¿¡æ¯ã€‚

## åˆ›å»º Kafka ç®¡ç†å®¢æˆ·ç«¯

åˆ›å»º Kafka ç®¡ç†å®¢æˆ·ç«¯çš„æ–¹æ³•ä¸ä½¿ç”¨åŸç”Ÿ Kafka å®¢æˆ·ç«¯åº“ååˆ†ç›¸ä¼¼ã€‚

æ‚¨éœ€è¦é…ç½®ä¸€äº›å±æ€§ï¼Œè¿™äº›å±æ€§å¯ä»¥å‚è§å®˜æ–¹çš„ Apache Kafka æ–‡æ¡£ï¼Œ å‚è€ƒæ­¤é“¾æ¥:https://kafka.apache.org/documentation/#adminclientconfigs[admin].

ä¸ºäº†ä¼ é€’é…ç½®ä¿¡æ¯ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä¸€ä¸ª Map æ¥ä¿å­˜å±æ€§å€¼ï¼Œ å¹¶åœ¨è°ƒç”¨ `KafkaAdminClient` æä¾›çš„é™æ€åˆ›å»ºæ–¹æ³•ä¼ å…¥ã€‚

```java
Properties config = new Properties();
config.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");

KafkaAdminClient adminClient = KafkaAdminClient.create(vertx, config);
```

## ä½¿ç”¨ Kafka ç®¡ç†å®¢æˆ·ç«¯

### è·å–ä¸»é¢˜åˆ—è¡¨

æ‚¨å¯ä»¥è°ƒç”¨ `listTopics` æ–¹æ³•æ¥è·å–é›†ç¾¤ä¸­çš„ä¸»é¢˜åˆ—è¡¨ã€‚ è¯¥æ–¹æ³•å”¯ä¸€éœ€è¦çš„å‚æ•°æ˜¯ä¸€ä¸ªå›è°ƒå‡½æ•°ç”¨äºå¤„ç†è¿”å›çš„ä¸»é¢˜åˆ—è¡¨ã€‚

```java
adminClient.listTopics().onSuccess(topics ->
    System.out.println("Topics= " + topics)
);
```

### ä¸»é¢˜æè¿°

æ‚¨å¯ä»¥è°ƒç”¨ `describeTopics` æ–¹æ³•æ¥è·å–é›†ç¾¤ä¸­çš„ä¸»é¢˜æè¿°ã€‚ ä¸»é¢˜æè¿°æ˜¯æŒ‡è·å–è¯¥ä¸»é¢˜ç›¸å…³çš„å…ƒæ•°æ®ï¼Œä¾‹å¦‚åˆ†ç‰‡æ•°é‡ï¼Œå‰¯æœ¬ï¼Œé¢†å¯¼ï¼ŒåŒæ­¥ä¸­çš„å‰¯æœ¬ç­‰ã€‚ æ–¹æ³•éœ€è¦çš„å‚æ•°æ˜¯æ‚¨è¦è·å–çš„ä¸»é¢˜åˆ—è¡¨å’Œç”¨äºå¤„ç†ç»“æœçš„å›è°ƒï¼Œ å›è°ƒä¼šé€šè¿‡ä¸€ä¸ª Map æ¥è¿”å›æŸ¥è¯¢ç»“æœï¼ŒMap çš„é”®æ˜¯ä¸»é¢˜åç§°ï¼ŒMap çš„å†…å®¹æ˜¯ `TopicDescription`ã€‚

```java
adminClient.describeTopics(Collections.singletonList("my-topic")).onSuccess(topics -> {
  TopicDescription topicDescription = topics.get("first-topic");

  System.out.println("Topic name=" + topicDescription.getName() +
      " isInternal= " + topicDescription.isInternal() +
      " partitions= " + topicDescription.getPartitions().size());

  for (TopicPartitionInfo topicPartitionInfo : topicDescription.getPartitions()) {
    System.out.println("Partition id= " + topicPartitionInfo.getPartition() +
      " leaderId= " + topicPartitionInfo.getLeader().getId() +
      " replicas= " + topicPartitionInfo.getReplicas() +
      " isr= " + topicPartitionInfo.getIsr());
  }
});
```

### åˆ›å»ºä¸»é¢˜

æ‚¨å¯ä»¥è°ƒç”¨ `createTopics` æ–¹æ³•åœ¨é›†ç¾¤ä¸­åˆ›å»ºä¸»é¢˜ï¼Œ æ–¹æ³•éœ€è¦çš„å‚æ•°æ˜¯æ‚¨è¦åˆ›å»ºçš„ä¸»é¢˜åˆ—è¡¨å’Œå¤„ç†ç»“æœçš„å›è°ƒã€‚ è¦åˆ›å»ºçš„ä¸»é¢˜éœ€è¦é€šè¿‡ `NewTopic` ç±»æ¥æŒ‡å®šåç§° åˆ†åŒºçš„æ•°é‡å’Œå¤åˆ¶å› å­ã€‚ ä¹Ÿå¯ä»¥æŒ‡å®šå‰¯æœ¬çš„åˆ†é…ï¼Œå°†å‰¯æœ¬æ˜ å°„ç»™æ¯ä¸ª Kafka æ¶ˆæ¯ä¸­ä»‹çš„ idï¼Œè€Œä¸æ˜¯ä»…è®¾ç½® åˆ†ç‰‡çš„æ•°é‡å’Œå¤åˆ¶é“¶å­ (åœ¨è¿™ç§æƒ…å†µä¸‹è¯¥å€¼ä¼šè¢«è®¾ç½®ä¸º -1)ã€‚

```java
adminClient.createTopics(Collections.singletonList(new NewTopic("testCreateTopic", 1, (short)1)))
  .onSuccess(v -> {
    // æˆåŠŸåˆ›å»ºä¸»é¢˜
  })
  .onFailure(cause -> {
    // åˆ›å»ºä¸»é¢˜æ—¶å‡ºé”™
  });
```

### åˆ é™¤ä¸»é¢˜

æ‚¨å¯ä»¥è°ƒç”¨ `deleteTopics` æ–¹æ³•æ¥åˆ é™¤é›†ç¾¤ä¸­çš„ä¸»é¢˜ã€‚ æ–¹æ³•éœ€è¦çš„å‚æ•°æ˜¯è¦åˆ é™¤çš„ä¸»é¢˜åˆ—è¡¨å’Œå¤„ç†ç»“æœçš„å›è°ƒã€‚

```java
adminClient.deleteTopics(Collections.singletonList("topicToDelete"))
  .onSuccess(v -> {
    // æˆåŠŸåˆ é™¤ä¸»é¢˜
  })
  .onFailure(cause -> {
    // åˆ é™¤ä¸»é¢˜æ—¶å‡ºé”™
  });
```

### é…ç½®æè¿°

æ‚¨å¯ä»¥è°ƒç”¨ `describeConfigs` æ–¹æ³•æ¥è·å–èµ„æºé…ç½®çš„æ•°æ®ã€‚ èµ„æºé…ç½®çš„æè¿°æ˜¯æŒ‡è·å–é›†ç¾¤ä¸­ä¸€äº›èµ„æºçš„ä¿¡æ¯ï¼Œä¾‹å¦‚ä¸»é¢˜å’Œæ¶ˆæ¯ä¸­ä»‹ã€‚ æ–¹æ³•éœ€è¦çš„å‚æ•°æ˜¯æ‚¨æƒ³è¦è·å–çš„èµ„æºåˆ—è¡¨å’Œç”¨äºå¤„ç†ç»“æœçš„å›è°ƒã€‚ èµ„æºé…ç½®é€šè¿‡ä¸€ä¸ªç±»å‹ä¸º `ConfigResource` çš„é›†åˆæè¿°ã€‚æ¯ä¸ªé…ç½®çš„æ•°æ® ä¿å­˜åœ¨ `Config` ç±»çš„ `ConfigEntry` é”®å€¼å¯¹ç±»å‹ä¸­

```java
adminClient.describeConfigs(Collections.singletonList(
  new ConfigResource(org.apache.kafka.common.config.ConfigResource.Type.TOPIC, "my-topic"))).onSuccess(configs -> {
  // æ£€æŸ¥é…ç½®
});
```

### é€‰æ‹©é…ç½®

æ‚¨å¯ä»¥è°ƒç”¨ `alterConfigs` æ–¹æ³•æ¥é€‰å–é›†ç¾¤çš„èµ„æºé…ç½®ã€‚ é€‰å–èµ„æºé…ç½®æ˜¯æŒ‡æ›´æ–°é›†ç¾¤èµ„æºçš„é…ç½®ä¿¡æ¯ï¼Œä¾‹å¦‚ä¸»é¢˜å’Œåˆ†åŒºã€‚ æ–¹æ³•éœ€è¦çš„å‚æ•°æ˜¯æ‚¨æƒ³æ›´æ–°çš„é…ç½®çš„èµ„æºåˆ—è¡¨å’Œç”¨äºå¤„ç†ç»“æœçš„å›è°ƒã€‚ æ‚¨å¯ä»¥åœ¨ä¸€æ¬¡æ–¹æ³•è°ƒç”¨ä¸­é€‰å–æ›´æ–°å¤šä¸ªä¸åŒèµ„æºçš„æ•°æ®ã€‚éœ€è¦çš„å‚æ•°æ˜¯ `ConfigResource` ä½œä¸ºèµ„æºå‚æ•°ä¸ `Config` ä½œä¸ºé…ç½®ä¸€ä¸€å¯¹åº”ã€‚

```java
ConfigResource resource = new ConfigResource(org.apache.kafka.common.config.ConfigResource.Type.TOPIC, "my-topic");
// åˆ›å»ºæ›´æ–°è¯¥ä¸»é¢˜ retention.ms çš„é…ç½®é¡¹
ConfigEntry retentionEntry = new ConfigEntry(TopicConfig.RETENTION_MS_CONFIG, "51000");
Map<ConfigResource, Config> updateConfig = new HashMap<>();
updateConfig.put(resource, new Config(Collections.singletonList(retentionEntry)));
adminClient.alterConfigs(updateConfig)
  .onSuccess(v -> {
    // æˆåŠŸæ›´æ–°é…ç§
  })
  .onFailure(cause -> {
    // é…ç½®æ›´æ–°æ—¶å‡ºé”™
  });
```

### æ¶ˆè´¹è€…ç¾¤ç»„åˆ—è¡¨

æ‚¨å¯ä»¥è°ƒç”¨ `listConsumerGroups` æ–¹æ³•æ¥è·å–é›†ç¾¤ä¸­çš„æ¶ˆè´¹è€…ç¾¤ç»„åˆ—è¡¨ã€‚ æ–¹æ³•éœ€è¦çš„å‚æ•°åªæœ‰ç”¨äºå¤„ç†æ¶ˆè´¹è€…ç¾¤ç»„åˆ—è¡¨ç»“æœçš„å›è°ƒã€‚

```java
adminClient.listConsumerGroups().onSuccess(consumerGroups ->
  System.out.println("ConsumerGroups= " + consumerGroups)
);
```

### æ¶ˆè´¹è€…ç¾¤ç»„çš„æè¿°

æ‚¨å¯ä»¥è°ƒç”¨ `describeConsumerGroups` æ¥è·å–æ¶ˆè´¹è€…ç¾¤ç»„çš„æè¿°ã€‚ æ¶ˆè´¹è€…ç¾¤ç»„çš„æè¿°æ˜¯æŒ‡è·å–æ¶ˆè´¹è€…ç¾¤ç»„çš„ç›¸å…³ä¿¡æ¯ï¼Œä¾‹å¦‚æˆå‘˜ï¼Œç›¸å…³çš„ idï¼Œä¸»é¢˜è®¢é˜…ï¼Œåˆ†åŒºåˆ†é…ç­‰ã€‚ éœ€è¦çš„å‚æ•°æ˜¯è¦è·å–æè¿°çš„æ¶ˆè´¹è€…ç¾¤ç»„åˆ—è¡¨å’Œç”¨äºå¤„ç†ç»“æœçš„å›è°ƒï¼Œ å›è°ƒä¼šé€šè¿‡ä¸€ä¸ª Map æ¥è¿”å›æŸ¥è¯¢ç»“æœï¼ŒMap çš„é”®æ˜¯æ¶ˆè´¹è€…ç¾¤ç»„çš„åç§°ï¼ŒMap çš„å€¼ç±»å‹æ˜¯ `MemberDescription` ã€‚

```java
adminClient.describeTopics(Collections.singletonList("my-topic")).onSuccess(topics -> {
  TopicDescription topicDescription = topics.get("first-topic");

  System.out.println("Topic name=" + topicDescription.getName() +
      " isInternal= " + topicDescription.isInternal() +
      " partitions= " + topicDescription.getPartitions().size());

  for (TopicPartitionInfo topicPartitionInfo : topicDescription.getPartitions()) {
    System.out.println("Partition id= " + topicPartitionInfo.getPartition() +
      " leaderId= " + topicPartitionInfo.getLeader().getId() +
      " replicas= " + topicPartitionInfo.getReplicas() +
      " isr= " + topicPartitionInfo.getIsr());
  }
});
```
